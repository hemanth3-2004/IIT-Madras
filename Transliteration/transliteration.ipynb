{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13557615,"sourceType":"datasetVersion","datasetId":8611470}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Embedding, LSTM, Dense, Concatenate, TimeDistributed, Lambda\n)\nimport numpy as np\nimport pandas as pd\nimport os\nimport sys\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:46:57.931724Z","iopub.execute_input":"2025-10-30T16:46:57.932014Z","iopub.status.idle":"2025-10-30T16:47:11.376518Z","shell.execute_reply.started":"2025-10-30T16:46:57.931993Z","shell.execute_reply":"2025-10-30T16:47:11.375728Z"}},"outputs":[{"name":"stderr","text":"2025-10-30 16:46:59.425102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761842819.626728      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761842819.686796      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n\nBASE_PATH = '/kaggle/input/aksharantar-sampled/aksharantar_sampled'\n\n# --- Automatic Language Discovery ---\nLANGUAGES_TO_TRAIN = []\nif os.path.exists(BASE_PATH):\n    all_items = os.listdir(BASE_PATH)\n    LANGUAGES_TO_TRAIN = [item for item in all_items \n                          if os.path.isdir(os.path.join(BASE_PATH, item)) and len(item) == 3]\n    LANGUAGES_TO_TRAIN.sort()\n    if not LANGUAGES_TO_TRAIN:\n        print(\"WARNING: Could not automatically detect languages. Falling back to default list.\")\n        LANGUAGES_TO_TRAIN = ['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\nelse:\n    print(f\"WARNING: Base path {BASE_PATH} not found. Falling back to default language list.\")\n    LANGUAGES_TO_TRAIN = ['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\n    \nprint(f\"Detected/Using Languages: {LANGUAGES_TO_TRAIN}\")\n\n\n# Training Hyperparameters\nBATCH_SIZE = 128            \nEPOCHS = 50                 \n\n# Model Hyperparameters\nR = EMBEDDING_DIM = 200     # R: Input embedding size\nS = HIDDEN_DIM = 128        # S: Hidden cell state size\nNUM_ENCODER_LAYERS = 1\nNUM_DECODER_LAYERS = 1\n\n# Data Handling Limit\nMAX_TRAINING_SAMPLES = float('inf')\n\n# Special Tokens\nSTART_TOKEN = '\\t'\nSTOP_TOKEN = '\\n'\n\nprint(f\"TensorFlow version: {tf.__version__}\")\n\n# CRITICAL SPEED FIX: Ensure eager execution is not enabled for performance\nos.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:49:50.160473Z","iopub.execute_input":"2025-10-30T16:49:50.161220Z","iopub.status.idle":"2025-10-30T16:49:50.177881Z","shell.execute_reply.started":"2025-10-30T16:49:50.161194Z","shell.execute_reply":"2025-10-30T16:49:50.177215Z"}},"outputs":[{"name":"stdout","text":"Detected/Using Languages: ['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\nTensorFlow version: 2.18.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def load_and_prepare_multilingual_data(languages, base_path):\n    \"\"\"Loads data, adds a 'Language' column, and combines all splits.\"\"\"\n    \n    all_train_data = []\n    all_valid_data = []\n    all_test_data = []\n    \n    print(f\"Loading data from directory: {base_path} for {len(languages)} languages...\")\n    \n    def load_file(lang, data_type, data_list):\n        \"\"\"Helper to load a single file and append its DataFrame to data_list.\"\"\"\n        filename = f'{lang}_{data_type}.csv'\n        path = os.path.join(base_path, lang, filename)\n        try:\n            df = pd.read_csv(path, header=None, encoding='utf-8')\n            df.columns = ['Latin', 'Native']\n            if len(df) > 0:\n                df['Language'] = lang \n                data_list.append(df)\n                return True\n        except FileNotFoundError:\n            pass\n        except Exception as e:\n            print(f\"ERROR loading {data_type} data for {lang}: {e}\")\n        return False\n\n    # Load data for all languages and splits\n    for lang in languages:\n        load_file(lang, 'train', all_train_data)\n        load_file(lang, 'valid', all_valid_data)\n        load_file(lang, 'test', all_test_data)\n\n    if not all_train_data:\n        sys.exit(\"CRITICAL ERROR: No training data could be loaded. Check BASE_PATH and file structure.\")\n\n    combined_train_df = pd.concat(all_train_data, ignore_index=True)\n    combined_valid_df = pd.concat(all_valid_data, ignore_index=True)\n    combined_test_df = pd.concat(all_test_data, ignore_index=True)\n    \n    return combined_train_df, combined_valid_df, combined_test_df\n\n# Execute data loading\ntrain_df, valid_df, test_df = load_and_prepare_multilingual_data(LANGUAGES_TO_TRAIN, BASE_PATH)\n\nprint(f\"Loaded {len(train_df)} training samples, {len(valid_df)} validation samples, and {len(test_df)} test samples.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:49:53.223355Z","iopub.execute_input":"2025-10-30T16:49:53.223628Z","iopub.status.idle":"2025-10-30T16:49:55.154339Z","shell.execute_reply.started":"2025-10-30T16:49:53.223607Z","shell.execute_reply":"2025-10-30T16:49:55.153706Z"}},"outputs":[{"name":"stdout","text":"Loading data from directory: /kaggle/input/aksharantar-sampled/aksharantar_sampled for 19 languages...\nLoaded 911513 training samples, 73051 validation samples, and 77809 test samples.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(\"\\n--- Data Cleaning and Sampling ---\")\n\ndef clean_dataframe(df):\n    \"\"\"Performs basic cleaning.\"\"\"\n    if df.empty:\n        return df\n    df['Latin'] = df['Latin'].astype(str).str.strip().str.lower()\n    df['Native'] = df['Native'].astype(str).str.strip()\n    df = df[df['Latin'].astype(bool) & df['Native'].astype(bool)]\n    return df\n\ntrain_df = clean_dataframe(train_df)\nvalid_df = clean_dataframe(valid_df)\ntest_df = clean_dataframe(test_df)\n\nprint(f\"Total Cleaned Training Samples: {len(train_df)}\")\n\nif len(train_df) > MAX_TRAINING_SAMPLES:\n    train_df = train_df.sample(int(MAX_TRAINING_SAMPLES), random_state=42).reset_index(drop=True)\n    print(f\"Applied Sampling: Training set reduced to {len(train_df)} samples.\")\n\n# Add start and stop tokens to all target sequences\nfor df in [train_df, valid_df, test_df]:\n    if not df.empty:\n        df['Target'] = df['Native'].astype(str).apply(lambda x: START_TOKEN + x + STOP_TOKEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:49:57.498214Z","iopub.execute_input":"2025-10-30T16:49:57.498891Z","iopub.status.idle":"2025-10-30T16:49:58.639295Z","shell.execute_reply.started":"2025-10-30T16:49:57.498870Z","shell.execute_reply":"2025-10-30T16:49:58.638676Z"}},"outputs":[{"name":"stdout","text":"\n--- Data Cleaning and Sampling ---\nTotal Cleaned Training Samples: 911513\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# ---  Vocabulary Generation ---\nsource_chars = set(char for word in train_df['Latin'] for char in str(word))\ntarget_chars = set(char for word in train_df['Target'] for char in str(word))\ntarget_chars.add(START_TOKEN)\ntarget_chars.add(STOP_TOKEN)\n        \nsource_chars = sorted(list(source_chars))\ntarget_chars = sorted(list(target_chars))\n\nsource_to_int = dict([(char, i + 1) for i, char in enumerate(source_chars)])\ntarget_to_int = dict([(char, i + 1) for i, char in enumerate(target_chars)])\n\nint_to_target = dict([(i, char) for char, i in target_to_int.items()])\nint_to_target[0] = '' # ID 0 is padding\n\nsource_vocab_size = len(source_chars) + 1\ntarget_vocab_size = len(target_chars) + 1\n\nlanguage_list = sorted(list(set(train_df['Language'].unique()) | set(valid_df['Language'].unique()) | set(test_df['Language'].unique())))\nlang_to_int = dict([(lang, i + 1) for i, lang in enumerate(language_list)])\nlang_vocab_size = len(language_list) + 1 \n\nall_latin = train_df['Latin'].tolist() + valid_df['Latin'].tolist() + test_df['Latin'].tolist()\nall_target = train_df['Target'].tolist() + valid_df['Target'].tolist() + test_df['Target'].tolist()\n\nmax_len_latin = max(len(str(w)) for w in all_latin) if all_latin else 1\nmax_len_target = max(len(str(w)) for w in all_target) if all_target else 1\n\nMAX_SEQUENCE_LENGTH = max(max_len_latin, max_len_target)\nL = MAX_SEQUENCE_LENGTH\n\nprint(f\"\\n--- Vocabulary and Sequence Stats ---\")\nprint(f\"Source Vocab Size (Latin): {source_vocab_size}\")\nprint(f\"Target Vocab Size (Native/V): {target_vocab_size}\")\nprint(f\"Language Vocab Size (U_lang): {lang_vocab_size}\")\nprint(f\"Max Sequence Length (L): {MAX_SEQUENCE_LENGTH}\")\n\n\ndef vectorize_data(df, max_len, source_to_int, target_to_int, lang_to_int):\n    \"\"\"Converts Latin, Target, and Language strings into ID sequences.\"\"\"\n    if df.empty:\n        return np.array([]), np.array([]), np.array([]), np.array([])\n        \n    N = len(df)\n    encoder_input_data = np.zeros((N, max_len), dtype='int32')\n    decoder_input_data = np.zeros((N, max_len), dtype='int32')\n    decoder_target_data = np.zeros((N, max_len), dtype='int32')\n    language_input_data = np.zeros((N, 1), dtype='int32') \n\n    for i, (latin, target, lang) in enumerate(zip(df['Latin'], df['Target'], df['Language'])):\n        latin = str(latin)\n        target = str(target)\n        \n        for t, char in enumerate(latin):\n            if t < max_len:\n                encoder_input_data[i, t] = source_to_int.get(char, 0)\n\n        for t, char in enumerate(target):\n            if t < max_len:\n                target_index = target_to_int.get(char, 0)\n                decoder_input_data[i, t] = target_index \n                \n                if t > 0:\n                    decoder_target_data[i, t - 1] = target_index\n\n        language_input_data[i, 0] = lang_to_int.get(lang, 0)\n        \n    return encoder_input_data, decoder_input_data, decoder_target_data, language_input_data\n\n# Vectorize all data splits\nencoder_input_train, decoder_input_train, decoder_target_train, language_input_train = vectorize_data(\n    train_df, L, source_to_int, target_to_int, lang_to_int)\n    \nencoder_input_valid, decoder_input_valid, decoder_target_valid, language_input_valid = vectorize_data(\n    valid_df, L, source_to_int, target_to_int, lang_to_int)\n    \nencoder_input_test, decoder_input_test, decoder_target_test, language_input_test = vectorize_data(\n    test_df, L, source_to_int, target_to_int, lang_to_int)\n\n# Create the tuple needed for Keras validation_data\nvalidation_data_tuple = ([encoder_input_valid, decoder_input_valid, language_input_valid], decoder_target_valid)\nif encoder_input_valid.size == 0:\n    print(\"WARNING: Validation set is empty, will train without dedicated validation data.\")\n    validation_data_tuple = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:50:01.436629Z","iopub.execute_input":"2025-10-30T16:50:01.437299Z","iopub.status.idle":"2025-10-30T16:50:09.974241Z","shell.execute_reply.started":"2025-10-30T16:50:01.437275Z","shell.execute_reply":"2025-10-30T16:50:09.973400Z"}},"outputs":[{"name":"stdout","text":"\n--- Vocabulary and Sequence Stats ---\nSource Vocab Size (Latin): 27\nTarget Vocab Size (Native/V): 681\nLanguage Vocab Size (U_lang): 20\nMax Sequence Length (L): 33\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def build_conditioned_seq2seq_model(R, S, U_src, U_tgt, U_lang):\n    \"\"\"\n    Builds the Seq2Seq model, conditioned on a Language ID input (U_lang).\n    \"\"\"\n    print(f\"\\n--- Building Language-Conditioned Seq2Seq Model (R={R}, S={S}) ---\")\n\n    # --- 4.1 Encoder (Latin Input) ---\n    encoder_inputs = Input(shape=(None,), name='encoder_input')\n    encoder_embedding = Embedding(U_src, R, mask_zero=True, name='latin_embed')(encoder_inputs)\n\n    # Encoder LSTM \n    encoder_outputs, state_h_enc, state_c_enc = LSTM(\n            S,\n            return_state=True,\n            return_sequences=False,\n            use_cudnn=False,\n            name='encoder_lstm_cell'\n        )(encoder_embedding)\n\n    # --- 4.2 Language Context ---\n    language_inputs = Input(shape=(1,), name='language_input')\n    lang_embedding = Embedding(U_lang, R // 2, mask_zero=False, name='lang_embed')(language_inputs)\n    \n    lang_context = Lambda(lambda x: tf.squeeze(x, axis=1), name='lang_context_vector')(lang_embedding)\n    \n    # Projection layers to match hidden state size S\n    lang_context_h = Dense(S, name='lang_context_h_proj', activation='relu')(lang_context)\n    lang_context_c = Dense(S, name='lang_context_c_proj', activation='relu')(lang_context)\n\n\n    # --- 4.3 Decoder Initial States (Conditioning) ---\n    decoder_h_initial = Concatenate(axis=-1, name='concat_h')([state_h_enc, lang_context_h])\n    decoder_c_initial = Concatenate(axis=-1, name='concat_c')([state_c_enc, lang_context_c])\n    \n    decoder_h_initial = Dense(S, activation='tanh', name='final_h_state')(decoder_h_initial)\n    decoder_c_initial = Dense(S, activation='tanh', name='final_c_state')(decoder_c_initial)\n    encoder_states = [decoder_h_initial, decoder_c_initial]\n\n\n    # --- 4.4 Decoder (Native Output) ---\n    decoder_inputs = Input(shape=(None,), name='decoder_input')\n    decoder_embedding = Embedding(U_tgt, R, mask_zero=False, name='native_embed')(decoder_inputs)\n    \n    decoder_outputs, _, _ = LSTM(\n        S,\n        return_sequences=True,\n        return_state=True,\n        use_cudnn=False,\n        name='decoder_lstm_cell')(decoder_embedding, initial_state=encoder_states)\n\n    decoder_dense = Dense(U_tgt, activation='softmax', name='output_dense')\n    decoder_outputs = TimeDistributed(decoder_dense)(decoder_outputs)\n    \n    # --- Training Model ---\n    training_model = Model([encoder_inputs, decoder_inputs, language_inputs], decoder_outputs)\n    \n    # --- Inference Models (for prediction) ---\n    # These models will be generated based on the training model's weights\n    # and kept in memory after training model is deleted for stability\n    encoder_model = Model([encoder_inputs, language_inputs], encoder_states)\n    \n    decoder_state_input_h = Input(shape=(S,), name='decoder_h_input')\n    decoder_state_input_c = Input(shape=(S,), name='decoder_c_input')\n    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\n    decoder_embedding_inf = training_model.get_layer('native_embed')(decoder_inputs)\n    \n    decoder_output_inf, state_h_inf, state_c_inf = training_model.get_layer('decoder_lstm_cell')(\n        decoder_embedding_inf, initial_state=decoder_states_inputs)\n\n    decoder_outputs_inf = TimeDistributed(decoder_dense)(decoder_output_inf)\n    \n    decoder_states = [state_h_inf, state_c_inf]\n    \n    decoder_model = Model(\n        [decoder_inputs] + decoder_states_inputs,\n        [decoder_outputs_inf] + decoder_states)\n        \n    return training_model, encoder_model, decoder_model\n\n# Build and compile the model\ntraining_model, encoder_model, decoder_model = build_conditioned_seq2seq_model(\n    R, S, source_vocab_size, target_vocab_size, lang_vocab_size)\n\n# Compile the training model\ntraining_model.compile(\n    optimizer='rmsprop',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'])\n\ntraining_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:50:09.975377Z","iopub.execute_input":"2025-10-30T16:50:09.975745Z","iopub.status.idle":"2025-10-30T16:50:12.168425Z","shell.execute_reply.started":"2025-10-30T16:50:09.975721Z","shell.execute_reply":"2025-10-30T16:50:12.167870Z"}},"outputs":[{"name":"stdout","text":"\n--- Building Language-Conditioned Seq2Seq Model (R=200, S=128) ---\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1761843010.793852      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ language_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_embed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │      \u001b[38;5;34m2,000\u001b[0m │ language_input[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ latin_embed         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │      \u001b[38;5;34m5,400\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_context_vector │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lang_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_cell   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │    \u001b[38;5;34m168,448\u001b[0m │ latin_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_context_h_proj │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m12,928\u001b[0m │ lang_context_vec… │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_context_c_proj │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m12,928\u001b[0m │ lang_context_vec… │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_h            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ encoder_lstm_cel… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lang_context_h_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_c            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ encoder_lstm_cel… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lang_context_c_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ native_embed        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │    \u001b[38;5;34m136,200\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ final_h_state       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ concat_h[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ final_c_state       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ concat_c[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_cell   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m168,448\u001b[0m │ native_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mLSTM\u001b[0m)              │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ final_h_state[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ final_c_state[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m681\u001b[0m) │     \u001b[38;5;34m87,849\u001b[0m │ decoder_lstm_cel… │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ language_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_embed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000</span> │ language_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ latin_embed         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,400</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_context_vector │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lang_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_lstm_cell   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">168,448</span> │ latin_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_context_h_proj │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ lang_context_vec… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lang_context_c_proj │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ lang_context_vec… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_h            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_lstm_cel… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lang_context_h_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_c            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_lstm_cel… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lang_context_c_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ native_embed        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">136,200</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ final_h_state       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ concat_h[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ final_c_state       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ concat_c[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_lstm_cell   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">168,448</span> │ native_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ final_h_state[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ final_c_state[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">681</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">87,849</span> │ decoder_lstm_cel… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m659,993\u001b[0m (2.52 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">659,993</span> (2.52 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m659,993\u001b[0m (2.52 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">659,993</span> (2.52 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"\n# # Define the directory for saving the best weights/models\n# MODEL_SAVE_DIR = \"conditioned_seq2seq_models\"\n\n# if not os.path.exists(MODEL_SAVE_DIR):\n#     os.makedirs(MODEL_SAVE_DIR)\n\n# # 5.1 Callbacks for optimization and tracking\n# callbacks = [\n#     # CRITICAL STABILITY FIX: Rely ONLY on restore_best_weights=True to keep the best model in memory.\n#     tf.keras.callbacks.EarlyStopping(\n#         monitor='val_loss',\n#         patience=5,\n#         verbose=1,\n#         mode='min',\n#         restore_best_weights=True \n#     ),\n#     tf.keras.callbacks.CSVLogger('training_log.csv', append=True)\n# ]\n\n\n# print(\"\\n--- Starting Model Training ---\")\n# print(\"NOTE: Training will run for up to 25 epochs or until EarlyStopping triggers.\")\n# print(\"*** WARNING: Model saving to disk has been DISABLED for maximum kernel stability. ***\")\n# print(\"The best weights are kept in memory and used for the inference models.\")\n\n\n# initial_epoch = 0\n\n# history = training_model.fit(\n#     [encoder_input_train, decoder_input_train, language_input_train],\n#     decoder_target_train,\n#     batch_size=BATCH_SIZE,\n#     epochs=EPOCHS,\n#     validation_data=validation_data_tuple,\n#     callbacks=callbacks, \n#     initial_epoch=initial_epoch,\n#     verbose=1\n# )\n\n\nimport os\nimport glob\nimport tensorflow as tf\n\n# Define directory for saving the best model\nMODEL_SAVE_DIR = \"conditioned_seq2seq_models\"\nif not os.path.exists(MODEL_SAVE_DIR):\n    os.makedirs(MODEL_SAVE_DIR)\n\nBEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, \"best_conditioned_seq2seq.h5\")\n\n\nclass CleanCheckpointCallback(tf.keras.callbacks.Callback):\n    def __init__(self, save_dir, monitor='val_loss', mode='min'):\n        super().__init__()\n        self.save_dir = save_dir\n        self.monitor = monitor\n        self.mode = mode\n        self.best = float('inf') if mode == 'min' else -float('inf')\n        self.best_model_path = os.path.join(save_dir, \"best_conditioned_seq2seq.h5\")\n\n    def on_epoch_end(self, epoch, logs=None):\n        current = logs.get(self.monitor)\n        if current is None:\n            return\n\n        improved = (current < self.best) if self.mode == 'min' else (current > self.best)\n        if improved:\n            self.best = current\n\n            # Remove any old checkpoints\n            for file in glob.glob(os.path.join(self.save_dir, \"*.h5\")):\n                if not file.endswith(\"best_conditioned_seq2seq.h5\"):\n                    try:\n                        os.remove(file)\n                    except Exception as e:\n                        print(f\"Could not remove old checkpoint {file}: {e}\")\n\n            # Save new best model\n            self.model.save(self.best_model_path)\n            print(f\"\\nEpoch {epoch+1}: Validation loss improved to {current:.4f}. Saved best model to {self.best_model_path}\")\n        else:\n            print(f\"Epoch {epoch+1}: No improvement (val_loss = {current:.4f})\")\n\ncallbacks = [\n    # Keeps best weights in memory\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        verbose=1,\n        mode='min',\n        restore_best_weights=True\n    ),\n    # Logs epoch-level performance to CSV\n    tf.keras.callbacks.CSVLogger('training_log.csv', append=True),\n    # Custom saver & cleaner\n    CleanCheckpointCallback(MODEL_SAVE_DIR, monitor='val_loss', mode='min')\n]\n\nprint(\"\\n--- Starting Model Training ---\")\nprint(\"Training will run for up to 25 epochs or until EarlyStopping triggers.\")\nprint(\"The best model will be automatically saved and older checkpoints removed.\\n\")\n\ninitial_epoch = 0\n\nhistory = training_model.fit(\n    [encoder_input_train, decoder_input_train, language_input_train],\n    decoder_target_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=validation_data_tuple,\n    callbacks=callbacks,\n    initial_epoch=initial_epoch,\n    verbose=1\n)\n\nprint(f\"\\nTraining complete. Best model saved to: {BEST_MODEL_PATH}\")\nprint(\"Best weights also remain loaded in memory for inference.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:50:50.154076Z","iopub.execute_input":"2025-10-30T16:50:50.154781Z","iopub.status.idle":"2025-10-30T16:53:27.338347Z","shell.execute_reply.started":"2025-10-30T16:50:50.154754Z","shell.execute_reply":"2025-10-30T16:53:27.337257Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Model Training ---\nTraining will run for up to 25 epochs or until EarlyStopping triggers.\nThe best model will be automatically saved and older checkpoints removed.\n\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1761843058.073149      97 service.cc:148] XLA service 0x7b0cdc0523a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1761843058.073810      97 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nW0000 00:00:1761843058.593977      97 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nI0000 00:00:1761843059.089036      97 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   3/7122\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 35ms/step - accuracy: 0.2717 - loss: 6.3850       ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1761843071.683983      97 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m7119/7122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7626 - loss: 1.0381","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1761843193.783049      98 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/479335241.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m history = training_model.fit(\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_input_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mdecoder_target_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL InternalError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/errors_impl.py(462): __init__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py(53): quick_execute\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py(1683): call_function\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py(139): call_function\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(878): _call\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(219): function\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(371): fit\n  /usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py(117): error_handler\n  /tmp/ipykernel_37/479335241.py(117): <cell line: 0>\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3553): run_code\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\n  /usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py(528): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py(383): do_execute\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(730): execute_request\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(406): dispatch_shell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(499): process_one\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(510): dispatch_queue\n  /usr/lib/python3.11/asyncio/events.py(84): _run\n  /usr/lib/python3.11/asyncio/base_events.py(1936): _run_once\n  /usr/lib/python3.11/asyncio/base_events.py(608): run_forever\n  /usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py(211): start\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py(712): start\n  /usr/local/lib/python3.11/dist-packages/traitlets/config/application.py(992): launch_instance\n  /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py(37): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n"],"ename":"RuntimeError","evalue":"pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL InternalError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/errors_impl.py(462): __init__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py(53): quick_execute\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py(1683): call_function\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py(139): call_function\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(878): _call\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(219): function\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(371): fit\n  /usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py(117): error_handler\n  /tmp/ipykernel_37/479335241.py(117): <cell line: 0>\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3553): run_code\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\n  /usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py(528): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py(383): do_execute\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(730): execute_request\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(406): dispatch_shell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(499): process_one\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(510): dispatch_queue\n  /usr/lib/python3.11/asyncio/events.py(84): _run\n  /usr/lib/python3.11/asyncio/base_events.py(1936): _run_once\n  /usr/lib/python3.11/asyncio/base_events.py(608): run_forever\n  /usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py(211): start\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py(712): start\n  /usr/local/lib/python3.11/dist-packages/traitlets/config/application.py(992): launch_instance\n  /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py(37): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"\n\nprint(\"\\n--- Aggressive Memory Cleanup (for Notebook Stability) ---\")\n# 1. Clear the Keras/TensorFlow session graph to free memory\ntf.keras.backend.clear_session()\n\n# 2. Explicitly delete large objects that are no longer needed\ndel encoder_input_train\ndel decoder_input_train\ndel decoder_target_train\ndel language_input_train\ndel encoder_input_valid\ndel decoder_input_valid\ndel decoder_target_valid\ndel language_input_valid\ndel training_model # Best weights were restored to the inference models by EarlyStopping\n\nprint(\"Memory cleared. Proceeding to Final Evaluation on Dedicated Test Set.\")\n\nif encoder_input_test.size > 0:\n    # Note: We use the smaller inference models for evaluation here, \n    # but since the full training model is often simpler to evaluate,\n    # we'll skip evaluation after cleanup to ensure maximum stability.\n    print(\"Skipping detailed re-evaluation to maintain environment stability.\")\nelse:\n    print(\"WARNING: No dedicated test data available for final evaluation.\")\n\n# --- Prediction Helper Functions (Needed for Section 7) ---\n\ndef decode_sequence_conditioned(input_seq, lang_id_seq):\n    \"\"\"Inference function to generate the target sequence character by character.\"\"\"\n    \n    # Use verbose=0 to prevent a console flood during the loop\n    states_value = encoder_model.predict([input_seq, lang_id_seq], verbose=0) \n    \n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = target_to_int[START_TOKEN]\n\n    stop_condition = False\n    decoded_sentence = ''\n    \n    while not stop_condition:\n        output_tokens_and_states = decoder_model.predict(\n            [target_seq] + states_value, verbose=0) \n        \n        output_tokens = output_tokens_and_states[0]\n        states_value = output_tokens_and_states[1:]\n        \n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = int_to_target.get(sampled_token_index, '?')\n\n        if sampled_token_index != 0:\n            decoded_sentence += sampled_char\n\n        if (sampled_char == STOP_TOKEN or len(decoded_sentence) > L):\n            stop_condition = True\n\n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n\n    return decoded_sentence.replace(STOP_TOKEN, '')\n\ndef transliterate_word_conditioned(word, lang):\n    \"\"\"Converts a Latin word string to an encoded input sequence and decodes it.\"\"\"\n    \n    input_seq = np.zeros((1, L), dtype='int32')\n    word = str(word).lower()\n    \n    for t, char in enumerate(word):\n        if t < L:\n            input_seq[0, t] = source_to_int.get(char, 0)\n            \n    lang_id = lang_to_int.get(lang, 0)\n    lang_id_seq = np.array([[lang_id]], dtype='int32')\n            \n    predicted_word = decode_sequence_conditioned(input_seq, lang_id_seq)\n    return predicted_word.strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nimport os\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"GENERATING SAMPLE TEST SET PREDICTIONS (50 samples from each language)\")\nprint(\"=\"*70)\n\nif test_df.empty:\n    print(\"Test DataFrame is empty. Cannot generate output CSV.\")\nelse:\n    tqdm.pandas()\n\n    SAMPLE_OUTPUT_PATH = \"sample_predictions.csv\"\n    SAMPLE_SIZE_PER_LANG = 50  # ← 50 per language\n\n    # --- Select 50 samples per language ---\n    lang_groups = test_df['Language'].unique()\n    sampled_frames = []\n\n    for lang in lang_groups:\n        lang_df = test_df[test_df['Language'] == lang]\n        n = min(len(lang_df), SAMPLE_SIZE_PER_LANG)\n        sampled_frames.append(lang_df.sample(n=n, random_state=42))\n\n    sample_df = pd.concat(sampled_frames, ignore_index=True)\n\n    print(f\"✅ Selected {len(sample_df)} samples from test data across {len(lang_groups)} languages.\\n\")\n\n    # --- Initialize output CSV ---\n    pd.DataFrame(columns=['Latin', 'Native', 'Language', 'Predicted', 'Match']).to_csv(\n        SAMPLE_OUTPUT_PATH, index=False\n    )\n\n    # --- Processing setup ---\n    save_interval = 10\n    display_interval = 1\n    buffer = []\n    total_rows = len(sample_df)\n    processed = {'count': 0}\n\n    def process_and_save(row):\n        processed['count'] += 1\n        predicted = transliterate_word_conditioned(row['Latin'], row['Language'])\n        match_flag = (row['Native'] == predicted)\n\n        buffer.append({\n            'Latin': row['Latin'],\n            'Native': row['Native'],\n            'Language': row['Language'],\n            'Predicted': predicted,\n            'Match': match_flag\n        })\n\n        # Display each prediction\n        if processed['count'] % display_interval == 0:\n            tqdm.write(\n                f\"[{processed['count']}/{total_rows}] \"\n                f\"Latin: '{row['Latin']}' | Predicted: '{predicted}' | \"\n                f\"Actual: '{row['Native']}' | Lang: {row['Language']}\"\n            )\n\n        # Periodically save\n        if processed['count'] % save_interval == 0 or processed['count'] == total_rows:\n            pd.DataFrame(buffer).to_csv(SAMPLE_OUTPUT_PATH, mode='a', index=False, header=False)\n            buffer.clear()\n            tqdm.write(f\" Saved progress up to row {processed['count']}\")\n\n        return predicted\n\n    # --- Run the processing loop ---\n    sample_df['Predicted'] = sample_df.progress_apply(process_and_save, axis=1)\n\n    # --- Final save if needed ---\n    if buffer:\n        pd.DataFrame(buffer).to_csv(SAMPLE_OUTPUT_PATH, mode='a', index=False, header=False)\n        buffer.clear()\n        tqdm.write(\"✅ Final buffer saved.\")\n\n    print(f\"\\nAll sample predictions saved to: {SAMPLE_OUTPUT_PATH}\")\n\n    # --- Preview of output ---\n    final_sample_df = pd.read_csv(SAMPLE_OUTPUT_PATH)\n    print(\"\\nHead of Sample Output:\")\n    print(final_sample_df.head(10).to_markdown(index=False))\n\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# print(\"\\n\" + \"=\"*70)\n# print(\"GENERATING FULL TEST SET PREDICTIONS AND SAVING OUTPUT CSV\")\n# print(\"=\"*70)\n\n# if test_df.empty:\n#     print(\"WARNING: Test DataFrame is empty. Cannot generate output CSV.\")\n# else:\n#     # --- PROGRESS BAR IMPLEMENTATION ---\n#     # 1. Enable TQDM integration with Pandas\n#     tqdm.pandas() \n    \n#     # 2. Use .progress_apply() instead of .apply() to show the progress bar\n#     print(f\"Running inference on {len(test_df)} test samples (using TQDM progress bar)...\")\n#     test_df['Predicted'] = test_df.progress_apply(\n#         lambda row: transliterate_word_conditioned(row['Latin'], row['Language']), \n#         axis=1\n#     )\n#     # -----------------------------------\n\n#     # Create the final output DataFrame with required columns\n#     output_df = test_df[['Latin', 'Native', 'Language', 'Predicted']].copy()\n    \n#     # Calculate word-level match for quality check\n#     output_df['Match'] = output_df['Native'] == output_df['Predicted']\n\n#     # --- Save to CSV ---\n#     OUTPUT_CSV_PATH = 'final_predictions.csv'\n#     output_df.to_csv(OUTPUT_CSV_PATH, index=False)\n#     print(f\"\\nSuccessfully saved all predictions to: {OUTPUT_CSV_PATH}\")\n    \n#     # --- Display Head 10 ---\n#     print(\"\\nHead 10 of the Final Output DataFrame:\")\n#     print(output_df.head(10).to_markdown(index=False))\n\n# print(\"=\"*70)\n\n\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport os\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"GENERATING FULL TEST SET PREDICTIONS AND SAVING OUTPUT CSV (DYNAMIC MODE + LIVE OUTPUT)\")\nprint(\"=\"*70)\n\nif test_df.empty:\n    print(\"WARNING: Test DataFrame is empty. Cannot generate output CSV.\")\nelse:\n    tqdm.pandas()\n    OUTPUT_CSV_PATH = \"final_predictions.csv\"\n    save_interval = 50       # save every N rows\n    display_interval = 1     # print every row (set to 5 or 10 to reduce output spam)\n    buffer = []\n\n    if not os.path.exists(OUTPUT_CSV_PATH):\n        pd.DataFrame(columns=['Latin', 'Native', 'Language', 'Predicted', 'Match']).to_csv(\n            OUTPUT_CSV_PATH, index=False\n        )\n\n    total_rows = len(test_df)\n    tqdm.write(f\"Running inference on {total_rows} test samples...\\n\")\n\n    processed = {'count': 0}\n\n    def process_and_save(row):\n        processed['count'] += 1\n\n        # Generate prediction\n        predicted = transliterate_word_conditioned(row['Latin'], row['Language'])\n        match_flag = (row['Native'] == predicted)\n\n        # Store for saving\n        buffer.append({\n            'Latin': row['Latin'],\n            'Native': row['Native'],\n            'Language': row['Language'],\n            'Predicted': predicted,\n            'Match': match_flag\n        })\n\n        # --- Print live output ---\n        if processed['count'] % display_interval == 0:\n            tqdm.write(\n                f\"[{processed['count']}/{total_rows}] \"\n                f\"Latin: '{row['Latin']}' | Predicted: '{predicted}' | \"\n                f\"Actual: '{row['Native']}' | Lang: {row['Language']}\"\n            )\n\n        # --- Save periodically ---\n        if processed['count'] % save_interval == 0 or processed['count'] == total_rows:\n            pd.DataFrame(buffer).to_csv(OUTPUT_CSV_PATH, mode='a', index=False, header=False)\n            buffer.clear()\n            tqdm.write(f\"Saved progress up to row {processed['count']}\")\n\n        return predicted\n\n    test_df['Predicted'] = test_df.progress_apply(process_and_save, axis=1)\n\n    if buffer:\n        pd.DataFrame(buffer).to_csv(OUTPUT_CSV_PATH, mode='a', index=False, header=False)\n        buffer.clear()\n        tqdm.write(\"Final buffer saved.\")\n\n    print(f\"\\nAll predictions processed and dynamically saved to: {OUTPUT_CSV_PATH}\")\n\n    # Preview first 10 saved rows\n    final_df = pd.read_csv(OUTPUT_CSV_PATH)\n    print(\"\\nHead 10 of the Final Output DataFrame:\")\n    print(final_df.head(10).to_markdown(index=False))\n\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}